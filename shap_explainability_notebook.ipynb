{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ed8c51",
   "metadata": {},
   "source": [
    "# SHAP Explainability Notebook â€” Loan Risk Assessment\n",
    "\n",
    "This notebook trains a RandomForest model and uses **SHAP** to explain model predictions. It is intended for inclusion in your GitHub repository as an explainability/demo notebook.\n",
    "\n",
    "**Dataset path:** `/mnt/data/Data_08_Simulated Loan Risk Assessment Data.csv`\n",
    "\n",
    "Run cells sequentially. If SHAP is not installed, run the install cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99763975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: (Optional) Install SHAP if not present\n",
    "# Uncomment and run if shap is not installed in your environment.\n",
    "# !pip install shap\n",
    "print('If SHAP is not installed, uncomment the pip install line above and run this cell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports and config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "try:\n",
    "    import shap\n",
    "except Exception as e:\n",
    "    print('shap import error (if missing, install shap):', e)\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "DATA_PATH = r\"/mnt/data/Data_08_Simulated Loan Risk Assessment Data.csv\"\n",
    "print('Data path:', DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load dataset and basic checks\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Shape:', df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
    "print('Numeric cols:', num_cols)\n",
    "print('Categorical cols:', cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Choose target and prepare y\n",
    "target = 'loan_status' if 'loan_status' in df.columns else ( [c for c in df.columns if df[c].nunique()<=10][0] if any(df[c].nunique()<=10 for c in df.columns) else None)\n",
    "print('Using target:', target)\n",
    "if target is None:\n",
    "    raise ValueError('No suitable target found in dataset. Please set target manually.')\n",
    "\n",
    "y = pd.factorize(df[target].fillna(df[target].mode()[0]))[0]\n",
    "print('Target value counts:', pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35344447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Basic preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_cols),\n",
    "    ('cat', categorical_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))])\n",
    "\n",
    "X = df.drop(columns=[target]).copy()\n",
    "print('Feature matrix shape before transform:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62dd731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Train-test split and fit model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:,1] if hasattr(clf.named_steps['classifier'], 'predict_proba') and len(np.unique(y))==2 else None\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1 score:', f1_score(y_test, y_pred, average='binary' if len(np.unique(y))==2 else 'macro'))\n",
    "if y_proba is not None:\n",
    "    print('ROC AUC:', roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba9f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Prepare data for SHAP (get feature names after preprocessing)\n",
    "pre = clf.named_steps['preprocessor']\n",
    "X_train_mat = pre.transform(X_train)\n",
    "X_test_mat = pre.transform(X_test)\n",
    "\n",
    "num_features = num_cols\n",
    "if cat_cols:\n",
    "    ohe = pre.named_transformers_['cat'].named_steps['onehot']\n",
    "    try:\n",
    "        cat_feature_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "    except Exception:\n",
    "        # older sklearn versions\n",
    "        cat_feature_names = list(ohe.get_feature_names(cat_cols))\n",
    "else:\n",
    "    cat_feature_names = []\n",
    "feature_names = num_features + cat_feature_names\n",
    "print('Total features after preprocessing:', len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90347e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: SHAP explainer (TreeExplainer for RF) and summary plot\n",
    "import shap\n",
    "rf_model = clf.named_steps['classifier']\n",
    "\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "shap_values = explainer.shap_values(X_test_mat)\n",
    "print('Computed SHAP values.')\n",
    "\n",
    "if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "    shap_vals_use = shap_values[1]\n",
    "else:\n",
    "    shap_vals_use = shap_values\n",
    "\n",
    "# Summary bar plot\n",
    "shap.summary_plot(shap_vals_use, X_test_mat, feature_names=feature_names, plot_type='bar', show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: SHAP dot summary and dependence plots for top features\n",
    "shap.summary_plot(shap_vals_use, X_test_mat, feature_names=feature_names, plot_type='dot', show=True)\n",
    "\n",
    "import numpy as np\n",
    "mean_abs_shap = np.abs(shap_vals_use).mean(axis=0)\n",
    "top_idx = np.argsort(mean_abs_shap)[-5:][::-1]\n",
    "top_features = [feature_names[i] for i in top_idx]\n",
    "print('Top features by mean(|SHAP|):', top_features)\n",
    "\n",
    "for feat in top_features[:3]:\n",
    "    shap.dependence_plot(feat, shap_vals_use, X_test_mat, feature_names=feature_names, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f06e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: SHAP force plot for a single sample and saving SHAP values\n",
    "i = 0\n",
    "try:\n",
    "    display(shap.force_plot(explainer.expected_value[1] if isinstance(shap_values, list) and len(shap_values)==2 else explainer.expected_value, shap_vals_use[i], X_test_mat[i], feature_names=feature_names))\n",
    "except Exception as e:\n",
    "    print('Force plot may require the JS visualization to be enabled in the notebook. Error:', e)\n",
    "\n",
    "shap_df = pd.DataFrame(shap_vals_use, columns=feature_names)\n",
    "shap_df.to_csv('/mnt/data/shap_values_test.csv', index=False)\n",
    "print('Saved SHAP values to /mnt/data/shap_values_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44638c5",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- If `shap` is missing, uncomment the pip install line in Cell 1. For GitHub, consider adding `requirements.txt` listing `shap`, `scikit-learn`, `pandas`, `numpy`, `matplotlib`, `seaborn`.\n",
    "- This notebook uses RandomForest; you can swap in LightGBM/XGBoost for improved performance and similar SHAP workflow.\n",
    "\n",
    "---\n",
    "\n",
    "You can download this notebook and push it to your GitHub repository."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
